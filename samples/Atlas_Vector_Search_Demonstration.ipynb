{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wh1hejLfqM3"
   },
   "source": [
    "## Atlas Vector Search\n",
    "\n",
    "Atlas Search's Vector Search capability provides developers the mechanism to **store** dense vectors, structured around certain algorithms (i.e. KNN), and an engine to **compute** similar vectors (i.e. euclidean distance) for relevance score calculation.\n",
    "\n",
    "Please review the [index definition](https://www.mongodb.com/docs/atlas/atlas-search/define-field-mappings-for-vector-search/#std-label-bson-data-types-knn-vector) and [query syntax](https://www.mongodb.com/docs/atlas/atlas-search/knn-beta/#options) documentation to learn more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ekss9o-fqM5"
   },
   "source": [
    "## Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3x4oLCkfqM5"
   },
   "source": [
    "We are a wholesaler of food suppplies and our largest customers are pizza franchises. They've been unfortunately complaining that their ingredient purchasers have spent way too much time searching for all the different types of cheeses.\n",
    "\n",
    "We will use Atlas' Vector Search capabilities to reduce the time spent searching for all cheeses manually, and instead just enter \"cheese\", where all the different types are returned automatically due to them being semantically similar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we do it today? \n",
    "\n",
    "There are really two approaches developers can use today, and that's via a tagging data structure or a synonyms mapping collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mappingType': 'explicit',\n",
       " 'input': ['Mozarella'],\n",
       " 'synonyms': ['cheese', 'dairy', 'pizza ingredient', 'fermented dairy', '...']}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tagging\n",
    "\n",
    "{\n",
    "    \"name\": \"Mozarella\",\n",
    "    \"tags\": [\"cheese\", \"dairy\", \"pizza ingredient\", \"fermented dairy\", \"...\"]\n",
    "}\n",
    "\n",
    "# synonyms\n",
    "\n",
    "{\n",
    "    \"mappingType\": \"explicit\",\n",
    "    \"input\": [\"Mozarella\"],\n",
    "    \"synonyms\": [\"cheese\", \"dairy\", \"pizza ingredient\", \"fermented dairy\", \"...\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both options require human or automated updating which have challenges with have challenges with consistency, management, and intuitiveness which all together results in a poor user experience. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZa6TaRufqM6"
   },
   "source": [
    "## Create the Vector Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QC1zByOpfqM6"
   },
   "source": [
    "<center><img width=\"700px\" src=\"index.png\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zGwneVXdfqM6",
    "outputId": "8aadbff4-99d0-47b2-efa4-a27ea8441af5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mappings': {'fields': {'embedding': [{'dimensions': 384,\n",
       "     'similarity': 'euclidean',\n",
       "     'type': 'knnVector'}]}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"mappings\": {\n",
    "    \"fields\": {\n",
    "      \"embedding\": [\n",
    "        {\n",
    "          \"dimensions\": 384,\n",
    "          \"similarity\": \"euclidean\",\n",
    "          \"type\": \"knnVector\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Field Mapping Parameters:\n",
    "- **dimensions:** The number of vector space dimensions which weâ€™ll enforce at index and query time. Represented as the number of floats in an array. Limited to 1024. \n",
    "- **similarity:** The vector similarity function used in search to determine the nearest neighbors. Options include: Euclidean, Dot product, and Cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PB-szRAffqM8"
   },
   "source": [
    "## Create Embeddings\n",
    "\n",
    "Let's create the embeddings that we'll use to store our products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from pprint import pprint\n",
    "\n",
    "# https://huggingface.co/obrizum/all-MiniLM-L6-v2\n",
    "# how is this converting?\n",
    "model = SentenceTransformer('obrizum/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_lUK0-AfqM9"
   },
   "outputs": [],
   "source": [
    "# strings as an array that we will\n",
    "products = [\n",
    "    {\"name\":\"Mozzarella\"},\n",
    "    {\"name\":\"Parmesan\"},\n",
    "    {\"name\":\"Cheddar\"},\n",
    "    {\"name\":\"Brie\"},\n",
    "    {\"name\":\"Swiss\"},\n",
    "    {\"name\":\"Gruyere\"},\n",
    "    {\"name\":\"Feta\"},\n",
    "    {\"name\":\"Gouda\"},\n",
    "    {\"name\":\"Provolone\"},\n",
    "    {\"name\":\"Monterey Jack\"},\n",
    "    {\"name\":\"Telephone\"}\n",
    "]\n",
    "\n",
    "# create a new embedding field for each product object\n",
    "for product in products:\n",
    "  # convert to embedding, then to array\n",
    "    embeddings = model.encode(product['name']).tolist()\n",
    "    product['embedding'] = embeddings\n",
    "    \n",
    "pprint(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzXPDLYYi8r0"
   },
   "source": [
    "## Store in Mongo\n",
    "\n",
    "Now we'll store this newly created array of objects with their corresponding product name embeddings in our collection one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HQzMjUURjUCX",
    "outputId": "644c5ee8-9e4e-4a70-c742-8bc352962b03"
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "mongo_uri = \"\"\n",
    "\n",
    "# connection object\n",
    "connection = pymongo.MongoClient(mongo_uri)\n",
    "database = 'eap'\n",
    "collection = 'vector'\n",
    "\n",
    "# delete all first\n",
    "# connection[database][collection].delete_many({})\n",
    "\n",
    "# insert\n",
    "# connection[database][collection].insert_many(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwY2xjchoTFe"
   },
   "source": [
    "## Query in Mongo Using KNN\n",
    "\n",
    "Lorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "gwP3G525oWXq",
    "outputId": "c6c647e3-7ae5-47f9-8975-5fbb9a1be7d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Cheddar', 'score': 0.627196729183197},\n",
      " {'name': 'Mozzarella', 'score': 0.6126944422721863},\n",
      " {'name': 'Swiss', 'score': 0.46435827016830444},\n",
      " {'name': 'Provolone', 'score': 0.4593936502933502},\n",
      " {'name': 'Monterey Jack', 'score': 0.44634753465652466},\n",
      " {'name': 'Gouda', 'score': 0.4415607750415802},\n",
      " {'name': 'Gruyere', 'score': 0.43056464195251465},\n",
      " {'name': 'Feta', 'score': 0.4289986193180084},\n",
      " {'name': 'Parmesan', 'score': 0.42754852771759033},\n",
      " {'name': 'Brie', 'score': 0.4135145843029022}]\n"
     ]
    }
   ],
   "source": [
    "query = \"cheese\"\n",
    "vector_query = model.encode(query).tolist()\n",
    "\n",
    "pipeline = [\n",
    "  {\n",
    "    \"$search\": {\n",
    "        \"index\":\"default\",\n",
    "      \"knnBeta\": {\n",
    "        \"vector\": vector_query,\n",
    "        \"path\": \"embedding\",\n",
    "        # limit the result set\n",
    "        \"k\": 10\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "{\n",
    "    \"$project\":{\n",
    "        \"embedding\":0,\n",
    "        \"_id\":0,\n",
    "        'score': {\n",
    "            '$meta': 'searchScore'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "]\n",
    "\n",
    "results = list(connection[database][collection].aggregate(pipeline))\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Review\n",
    "\n",
    "Review this diagram to understand how Atlas Vector Search plays within your search architecture:\n",
    "\n",
    "<center><img src=\"diagram.png\" style=\"padding-top:1em\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Queries\n",
    "\n",
    "What if we want to prioritize documents that contain more exact string matches in addition to the above contextual vector search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Cheddar', 'score': 0.627196729183197},\n",
      " {'name': 'Mozzarella', 'score': 0.6126944422721863},\n",
      " {'name': 'Swiss', 'score': 0.46435827016830444},\n",
      " {'name': 'Provolone', 'score': 0.4593936502933502},\n",
      " {'name': 'Monterey Jack', 'score': 0.44634753465652466},\n",
      " {'name': 'Gouda', 'score': 0.4415607750415802},\n",
      " {'name': 'Gruyere', 'score': 0.43056464195251465},\n",
      " {'name': 'Feta', 'score': 0.4289986193180084},\n",
      " {'name': 'Parmesan', 'score': 0.42754852771759033},\n",
      " {'name': 'Brie', 'score': 0.4135145843029022}]\n"
     ]
    }
   ],
   "source": [
    "string_match_query = \"Telephone\"\n",
    "\n",
    "# lets first insert an exact match\n",
    "# connection[database][collection].insert_one({\"name\":string_match_query})\n",
    "\n",
    "# what products include cheese?\n",
    "# let's update the index definition with this static mapping:\n",
    "{\n",
    "  \"mappings\": {\n",
    "    \"fields\": {\n",
    "      \"embedding\": [{\n",
    "        \"dimensions\": 384,\n",
    "        \"similarity\": \"euclidean\",\n",
    "        \"type\": \"knnVector\"\n",
    "      }],\n",
    "      \"name\": {\n",
    "        \"type\": \"string\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# now we combine queries using a score boost\n",
    "pipeline = [{\n",
    "    \"$search\": {\n",
    "      \"compound\": {\n",
    "        \"should\": [{\n",
    "            \"knnBeta\": {\n",
    "              \"vector\": vector_query,\n",
    "              \"path\": \"embedding\",\n",
    "              \"k\": 10\n",
    "            }\n",
    "          },\n",
    "          {\n",
    "            \"text\": {\n",
    "              \"query\": \"Telephone\",\n",
    "              \"path\": \"name\",\n",
    "              \"score\": {\"boost\": {\"value\": 10}\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"$project\": {\n",
    "      \"embedding\": 0,\n",
    "      \"_id\": 0,\n",
    "      'score': {\n",
    "        '$meta': 'searchScore'\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "]\n",
    "\n",
    "results = list(connection[database][collection].aggregate(pipeline))\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similarity score matrix plot\n",
    "\n",
    "Keep the initial query like now. Beneath, mention that now k = 20 and here's the plot of result item rank (x-axis) and score (y-axis). Not sure what the optimal number of examples would be, but maybe go for k = 20, 50, 100 with this structure? (edited)\n",
    "\n",
    "dimensionality vs size of the index vs relevance vs speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Cheddar', 'score': 0.627196729183197},\n",
      " {'name': 'Mozzarella', 'score': 0.6126944422721863},\n",
      " {'name': 'Swiss', 'score': 0.46435827016830444},\n",
      " {'name': 'Provolone', 'score': 0.4593936502933502},\n",
      " {'name': 'Monterey Jack', 'score': 0.44634753465652466},\n",
      " {'name': 'Gouda', 'score': 0.4415607750415802},\n",
      " {'name': 'Gruyere', 'score': 0.43056464195251465},\n",
      " {'name': 'Feta', 'score': 0.4289986193180084},\n",
      " {'name': 'Parmesan', 'score': 0.42754852771759033},\n",
      " {'name': 'Brie', 'score': 0.4135145843029022},\n",
      " {'name': 'Telephone', 'score': 0.4124469757080078}]\n"
     ]
    }
   ],
   "source": [
    "#Let's now modify the k value to see how it impacts the item rank and score\n",
    "\n",
    "query = \"cheese\"\n",
    "vector_query = model.encode(query).tolist()\n",
    "\n",
    "pipeline = [\n",
    "  {\n",
    "    \"$search\": {\n",
    "      \"knnBeta\": {\n",
    "        \"vector\": vector_query,\n",
    "        \"path\": \"embedding\",\n",
    "        \"k\": 12\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "{\n",
    "    \"$project\":{\n",
    "        \"embedding\":0,\n",
    "        \"_id\":0,\n",
    "        'score': {\n",
    "            '$meta': 'searchScore'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "]\n",
    "\n",
    "results = list(connection[database][collection].aggregate(pipeline))\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index definition\n",
    "{\n",
    "  \"mappings\": {\n",
    "    \"dynamic\": true,\n",
    "    \"fields\": {\n",
    "      \"teachers\": [\n",
    "        {\n",
    "          \"dynamic\": true,\n",
    "          \"fields\": {\n",
    "            \"vector\": {\n",
    "              \"dimensions\": 3,\n",
    "              \"similarity\": \"euclidean\",\n",
    "              \"type\": \"knnVector\"\n",
    "            }\n",
    "          },\n",
    "          \"type\": \"embeddedDocuments\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# docs\n",
    "{\n",
    "  \"teachers\": [\n",
    "    {\n",
    "      \"first\": \"Jane\",\n",
    "      \"last\": \"Smith\",\n",
    "      \"vector\": [\n",
    "        1,\n",
    "        1,\n",
    "        1\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "# query\n",
    "[\n",
    "    {\n",
    "        '$search': {\n",
    "            'index': 'embedded_vector', \n",
    "            'embeddedDocument': {\n",
    "                'path': 'teachers', \n",
    "                'operator': {\n",
    "                    'compound': {\n",
    "                        'filter': [\n",
    "                            {\n",
    "                                'text': {\n",
    "                                    'path': 'teachers.first', \n",
    "                                    'query': 'John'\n",
    "                                }\n",
    "                            }, {\n",
    "                                'text': {\n",
    "                                    'path': 'teachers.last', \n",
    "                                    'query': 'Smith'\n",
    "                                }\n",
    "                            }\n",
    "                        ], \n",
    "                        'should': [\n",
    "                            {\n",
    "                                'knnBeta': {\n",
    "                                    'path': 'teachers.vector', \n",
    "                                    'k': 10, \n",
    "                                    'vector': [\n",
    "                                        6, 6, 6\n",
    "                                    ]\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Atlas Vector Search Demonstration.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
