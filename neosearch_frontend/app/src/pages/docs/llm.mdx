# Configure LLM - Large Language Model

In this app, LLM is used for several purposes:
1. Extracting knowledge from docs;
2. Generating responses to user queries.

## Configure the LLM

After login with admin account, you can configure the LLM in the admin panel.

1. Go to the admin panel;
2. Click on the `LLMs` tab;
3. Click on the `+ New` button to add a new LLM;

![llm-config](https://github.com/user-attachments/assets/118fe7ba-c0fd-459c-ad2c-12c5afba05ef "LLM Config")

4. Input your LLM information and click `Create LLM` button;
5. Done!

import { Callout } from 'nextra/components'

<Callout>
If you want to use the new LLM while answering user queries, you need switch to `Chat Engines` tab and set the new LLM as LLM.
</Callout>

## Supported LLMs

Currently we support the following LLMs:

- [OpenAI](https://platform.openai.com/)
- [Gemini](https://gemini.google.com/)
- OpenAI Like
    - [OpenRouter](https://openrouter.ai/)
        - Default config: `{"api_base": "https://openrouter.ai/api/v1/"}`
    - [BigModel](https://open.bigmodel.cn/)
        - Default config:
        ```json
        {
            "api_base": "https://open.bigmodel.cn/api/paas/v4/",
            "is_chat_model": true
        }
        ```
- [Bedrock](https://aws.amazon.com/bedrock/)
- [Anthropic Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/use-claude)
- [Ollama](https://ollama.com/)
    - Default config: `{"base_url": "http://localhost:11434"}`
